#!/usr/bin/env python3
"""
Test script for Groq integration with the new model and parameters
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.llm_service import llm_service
from app.config import settings

def test_groq_initialization():
    """Test Groq client initialization"""
    print("ğŸ”§ Testing Groq Client Initialization...")
    
    try:
        # Check if Groq API key is set
        if not settings.groq_api_key:
            print("âŒ GROQ_API_KEY not set in environment")
            print("ğŸ’¡ Please set your Groq API key in the .env file")
            return False
        
        # Test client initialization
        print(f"âœ… Provider: {llm_service.provider}")
        print(f"âœ… Model: {llm_service.model}")
        print(f"âœ… Client initialized successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Failed to initialize Groq client: {e}")
        return False

def test_groq_simple_query():
    """Test a simple query with Groq"""
    print("\nğŸ§ª Testing Simple Groq Query...")
    
    try:
        # Simple test prompt
        test_prompt = "Hello! Please respond with a brief greeting and tell me what you can help with."
        
        print("ğŸ“¤ Sending query to Groq...")
        response = llm_service._call_groq(test_prompt, stream=False)
        
        print("ğŸ“¥ Response received:")
        print("-" * 50)
        print(response)
        print("-" * 50)
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to get response from Groq: {e}")
        return False

def test_groq_streaming():
    """Test streaming response with Groq"""
    print("\nğŸŒŠ Testing Groq Streaming Response...")
    
    try:
        # Test prompt for streaming
        test_prompt = "Please explain the benefits of using AI for invoice analysis in a detailed way."
        
        print("ğŸ“¤ Sending streaming query to Groq...")
        print("ğŸ“¥ Streaming response:")
        print("-" * 50)
        
        response = llm_service._call_groq(test_prompt, stream=True)
        print(response)
        print("-" * 50)
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to get streaming response from Groq: {e}")
        return False

def test_invoice_analysis_prompt():
    """Test invoice analysis prompt with Groq"""
    print("\nğŸ“Š Testing Invoice Analysis with Groq...")
    
    try:
        # Sample policy and invoice text
        policy_text = """
        IAI Solution Employee Reimbursement Policy
        Food & Beverages: â‚¹200 per meal
        Travel Expenses: â‚¹2,000 per trip
        Daily Cab: â‚¹150 per day
        Accommodation: â‚¹50 per night
        """
        
        invoice_text = """
        Restaurant Bill
        Business lunch meeting
        Amount: â‚¹180
        Date: 2024-01-15
        """
        
        # Create analysis prompt
        prompt = llm_service._create_analysis_prompt(policy_text, invoice_text, "test_invoice.pdf")
        
        print("ğŸ“¤ Sending invoice analysis query to Groq...")
        response = llm_service._call_groq(prompt, stream=False)
        
        print("ğŸ“¥ Analysis response:")
        print("-" * 50)
        print(response)
        print("-" * 50)
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to analyze invoice with Groq: {e}")
        return False

def main():
    """Main test function"""
    print("ğŸš€ Groq Integration Test")
    print("=" * 50)
    
    # Test 1: Initialization
    if not test_groq_initialization():
        return
    
    # Test 2: Simple query
    if not test_groq_simple_query():
        return
    
    # Test 3: Streaming
    if not test_groq_streaming():
        return
    
    # Test 4: Invoice analysis
    if not test_invoice_analysis_prompt():
        return
    
    print("\nğŸ‰ All Groq integration tests passed!")
    print("\nğŸ’¡ Your Groq integration is working correctly!")
    print("   You can now use the system with the new 'deepseek-r1-distill-llama-70b' model.")

if __name__ == "__main__":
    main() 